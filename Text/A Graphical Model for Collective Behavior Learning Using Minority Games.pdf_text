A Graphical Model for Collective Behavior

Learning Using Minority Games

Farhan Khawar and Zengchang Qin

Intelligent Computing and Machine Learning Lab
School of ASEE, Beihang University, Beijing, China

farhan.khawar@asee.buaa.edu.cn, zcqin@buaa.edu.cn

Abstract. The Minority Game (MG) is a simple game theory model
for the collective behavior of agents in an idealized situation where they
compete for some ﬁnite resource. In this paper, we assume that collective
behavior is determined by the aggregation of individual actions of agents.
This causal relation between collective behavior and individual actions
is investigated. A graphical model is proposed to model the generative
process of collective behavior using a group of agents whose actions are
modeled by minority games. In this model, we can infer the individ-
ual behavior of the agents by training on the global information, and
then make predictions about the future collective behavior. Experimen-
tal results on a set of stock indexes from the Chinese market and foreign
exchange (FX) rates show that the new proposed model can eﬀectively
capture the rises and falls of market and be signiﬁcantly better than
a random predictor. This framework also provides a new data mining
paradigm for analyzing collective data by modeling micro-level actions
of agents using game theory models.

Keywords: Collective Intelligence, Minority Game, Probabilistic Graph-
ical Models.

1

Introduction

Collective intelligence is a shared or group intelligence that emerges from the in-
teractions (both collaborative and competitive) of many individuals and appears
in consensus decision making of agents. Collective behaviors can be modeled by
agent-based games where each individual agent follows its own local rules. Agent-
based experimental games have attracted much attention in diﬀerent research
areas, such as psychology [1], economics [2,3], ﬁnancial market modeling [4,5]
and market mechanism designs [6,7]. Agent-based models (ABM) of complex
adaptive systems (CAS) provide invaluable insight into the highly non-trivial
collective behavior of a population of competing agents. These systems are uni-
versal and researchers aim to model the systems where involving agents with
similar capability are competing for a limited resource. Agents may share global
information and learn from past experience. In such a complex system, if we
assume that every agent in the market knows the history data, the key problem
is how to decide to act based on this global information.

V.S. Tseng et al. (Eds.): PAKDD 2014, Part II, LNAI 8444, pp. 284–295, 2014.
c(cid:2) Springer International Publishing Switzerland 2014

A Graphical Model for Collective Behavior Learning Using Minority Games

285

The minority game [8] is a simple ABM originating from the El-Farol Bar
[9] problem. An odd number of agents compete with each other to be in the
minority by making one of two choices; the players who end up in the minority
side win the game. The collective recognizable patterns generated by the minority
game are due to the interaction of many individual agents. There are two main
features for the minority game: ﬁrst, the minority rule, which makes complete
steady state in the population impossible and secondly, every agent has its own
way of perceiving the available global information about the game and using
it into its own strategy. Each agent is aware of the global information and can
use this information to make decisions based on its own unique strategy, as it
is unrealistic that all agents follow the same deterministic strategy [10]. Due to
its simplicity and attractive properties, the minority game model has attracted
much attention in diﬀerent research communities [11].

In [12] the authors purpose that collective behaviors of MG can be decom-
posed into several micro-level behaviors from diﬀerent group of agents and they
use Genetic Algorithm (GA) to optimize the agent behavior parameters in order
to get the best guess of the original system. Also, diﬀerent game theory model
can be used to model the individual behavior. More accurate a model is for
individual behavior, more accurate collective behavior we can obtain [13]. Un-
certainty is present in all real-world scenarios, especially when it comes to the
task of predicting the outcomes of aggregated actions. Probabilistic graphical
models (PGM) [14] have the capability to deal with uncertainty by incorporat-
ing prior beliefs about the domain and updating these beliefs as new evidence is
obtained. Using PGMs we can construct richly structured models to understand
hidden relations.

In this paper, we propose a novel generative probabilistic graphical model for
modeling the process of generation of the collective behavior from the individual
behavior. We use the proposed PGM to infer the behavior of individual agents
from the available global information and use the learned agent behavior to pre-
dict the future collective behavior. The main contribution of our work is four
fold: (1) We use a game theory model, the minority game, to model individual
behavior. It also has the ﬂexibility of using any appropriate game theories to
model individual behavior; (2) A PGM is used to model generative process of
collective data from a group of individual actions. We can infer the individual
strategy from the observable collective data, and this can be used for predict-
ing future collective data; (3) We use this novel framework to show how it can
be applied to time-series data mining of ﬁnancial market data; (4) Comprehen-
sive experiments on real world stock market data and foreign exchange rates
demonstrate the eﬀectiveness of the new model.

2 Behavior Modeling Using Minority Game

In a MG, there are an odd number of players and each player must independently
choose one of two options at each round of the game, the players who end up at
the minority side are winners and the choice of the minority players is referred

286

F. Khawar and Z. Qin

to as the winning choice r. There is no prior communication among players; the
only global information available is numbers of players corresponding to the two
choices from the previous rounds.

2.1 Terminology

We begin by ﬁrst introducing the notation and the terminology used in this
paper: Agent : A player of the game is referred to as an “agent” and it is the
entity that makes decisions based on its “strategy”. The number of agents that
participate in the MG is N , which is an odd number. Agent is indexed by an
integer A where A ∈ {1, 2, . . . , N}.
C ∈ {0, 1}. The total number of choices are N .
Game: Every run of the MG will be referred to as a “game”. In every game
the choices are represented as a vector of N elements of binary value {0, 1}. It
can also be viewed as a sequence of choices C1, C2, . . . , CN where Cn is the nth
agent’s choice in the game. The total number of games is denoted by G.

Choice: An action made by an agent. Choice C has two possible values:

Minority Choice: For every game the choice of the agents on the minority
side is the winning outcome and is called the “minority choice”. Formally, let t
denote the current game, then the minority choice in game t is deﬁned by:

(cid:2)

(cid:3)N

If

r(t) =

0
1 Otherwise

n=1

Cn(t) > N
2

(1)

Memory and History: In the minority game we assume that the agent’s
actions are governed by its strategy and previous minority choices of the game.
If the agents have an m-bit memory which means that the agent will take into
the information (minority choices) in the previous m rounds. The minority choice
for the last m round of games is deﬁned as the “history” H ∈ {1, 2, 3, . . . , K}
and K = 2m, where K is the maximum value of history. History is normally
a binary string of the past m minority choices, but without loss of generality,
for the representational convenience of our model we have deﬁned history as a
decimal number. For example if the agents have a 3-bit memory then the history
belongs to the set H = {1, 2, 3, . . . , 8}.

Strategy: We assume that each agent’s action is governed by a strategy
which can be regarded as a set of rules or functions taking the previous minority
choices as inputs. Given a history, the agent makes its decision based on its own
predeﬁned rules named “strategy” S [8,15,16]. The strategy is a mapping from
each possible m-bit memory(each possible history) to a corresponding choice
of making choice-0 or choice-1. Therefore, there are 22m
possible strategies in
the strategy space and we assume that at one time each agent has exactly one
strategy. A strategy can be regarded as a particular set of decisions on all the
permutations of previous history of minority choices. Fo r example, the ﬁrst 3
rows of Table 1 show the 3-bit memory, history and a sample strategy.

Probabilistic Strategy: For each agent, “probabilistic strategy (PS)” is a
strategy that maps the history to a probability distribution over the two choices

A Graphical Model for Collective Behavior Learning Using Minority Games

287

Table 1. Sample strategy and PS of one agent for 3-bit memory and history

Memory (000)2
History
Strategy
PS

1
1

(001)2

(010)2

(011)2

(100)2

(101)2

(110)2

(111)2

2
0

3
1

4
1

5
0

6
0

7
0

8
1

PB(0.1) PB(0.8) PB(0.3) PB(0.1) PB(0.6) PB(0.8) PB(0.6) PB(0.3)

instead of mapping directly to one choice only. We use a Bernoulli distribution to
represent probabilistic strategy. The bottom row of Table 1 shows a sample PS
where PB(p) represents a Bernoulli distribution, p is the probability of making
choice-0 and q = 1 − p is the probability of making choice-1.The advantage of
using such a strategy is that it is able to incorporate uncertainty in the learning
process of the PS via PGMs, because for the next game this PS provide a prior
to the PGM.

2.2 Probabilistic Graphical Model for Collective Behavior Learning

Previous works show that collective behavior can be decomposed into the ag-
gregation of individual agents’ actions [12,13]. In this paper we assume that the
collective behavior is generated by agents with probabilistic strategies. Our task
is two fold: ﬁrst, to decompose the collective behavior by inferring individual
agent behaviors, and the second, to use these learned individual behaviors to
predict the future collective behavior. PGMs provide us the ability to deal with
uncertainty and incorporate prior knowledge. Moreover, the proposed PGM will
provide a uniﬁed framework for both the inference of individual behaviors and
the prediction of the global behavior.

With this premise,the motivation behind our purposed PGM is to model the
procedure of an agent making a choice. We ﬁrst start by drawing a distribution
over agents from a Dirichlet prior, then we randomly select an agent from this
agent distribution to make a choice. After selecting this agent we observe the
history for the present game. Then the agent’s choice, corresponding to the
observed history, is sampled from its PS. This is repeated N times to generate
all the choices of a game. Formally this generative process can be outlined as:

– For each agent and each history:

• Draw a vector of distribution over the two choices φn,k ∼ Dir2 (β) from

a Dirichlet prior.

– Observe the history H for the current game.
– For each choice

DirN (α).

• Draw a vector of agent distribution from a Dirichlet prior i.e. ψn ∼
• Draw an agent index An ∼ M ult(ψn) , An ∈ {1, . . . , N}.
• Draw a choice Cn ∼ Bernoulli(φAn,H ), Cn ∈ {0, 1}.

where α and β are scalars that parameterize the symmetric prior Dirichlet dis-
tributions, Dir2 (β) denotes a 2-dimensional Dirichlet with the scalar parameter

288

F. Khawar and Z. Qin

β and DirN (α) denotes an N dimensional Dirichlet parameterized by α. A sym-
metric Dirichlet is a Dirichlet distribution where every component of the param-
eter is equal to the same scalar value. The Dirichlet distribution is a distribution
over discrete distributions and it is conjugate to the Multinomial distribution;
each component in the sampled random vector is the probability of drawing the
item associated with that component. M ult(.) denotes a discrete Multinomial
distribution.

The “choice distribution” φn,k is a 2-dimensional random vector that corre-
sponds to the probability of making choice-0 or choice-1 for agent n and history
k. For a single agent n, the set of these distributions for all values of history
corresponds to that agent’s PS i.e. {φn,m=1,...,K} is the PS of agent n. The dis-
tribution ψn is the “agent distribution” and is a N -dimensional random vector
where each component gives the probability of selecting the agent index associ-
ated with that component. The corresponding directed graphical model is shown

Fig. 1. Graphical model representation

in Figure 1. It is worth mentioning here that the choices that are observed are
unordered choices: the N choices for every game are provided as a string of 0’s
followed by 1’s. If the actual choices made by the N =5 agents were [1,0,1,0,0]
in one game and [0,1,1,0,0] in the other game then in both cases the observed
choices would be [0,0,0,1,1]. These unordered choices are referred to as choices
throughout the paper.

The joint distribution corresponding to the PGM in Figure 1 is:

n=1

Notice that since H is observed and does not depend on another variable. It
is a deterministic variable and p(H) can be omitted from the joint of Eq. (2).
The model speciﬁes a number of dependencies between random variables: the
agent index An depends on agent distribution ψn, the choices Cn depends on the

(2)

N(cid:4)

K(cid:4)

p(ψ1:N , A1:N , φ1:N,1:K, C1:N , H|α, β, H) =

p(φi,k|β)
(cid:6)
p(ψn|α)p(An|ψn)p(Cn|An, φ1:N,1:K, H)

k=1

i=1

(cid:5)

N(cid:4)

p(H)

A Graphical Model for Collective Behavior Learning Using Minority Games

289

agent index An , history H and all of the choice distributions φ1:N,1:K. Here the
notation φ1:N,1:K denotes the set of distributions {φn,k|0 < n ≤ N , 0 < k ≤ K}.
This is equivalent to saying that p(Cn|An, φ1:N,1:K, H) = φAn,H i.e. from the PS
of the agent denoted by An we ﬁnd the choice distribution corresponding to the
observed history H. From Figure 1 we can also see that once choices are ob-
served the agent distributions ψn and choice distributions φn,k are conditionally
dependent according to d-separation.

3

Inference and Prediction

In generative probabilistic modeling, we treat our data as arising from a genera-
tive process that includes hidden and observed variables. This generative process
deﬁnes a joint probability distribution over both the observed and latent random
variables. We perform data analysis by using that joint distribution to compute
the conditional distribution of the latent variables given the observed variables.
The decomposition of collective behavior to individual behavior corresponds to
observing the choices and history and inferring the posterior distribution of the
hidden variables. The choices and the history are the global behavior and the

posterior of the agent distributions p(ψ1:N|C1:N , H) and choice distributions
p(φ1:N,1:K|C1:N , H) are the local behaviors. Here the notation ψ1:N denotes the
set of distributions {ψn|0 < n ≤ N} = {ψ1, ψ2, . . . , ψN}. The posterior distribu-

tion can be written as:

p(ψ1:N , A1:N , φ1:N,1:K|C1:N , H, α, β) =

p(ψ1:N , A1:N , φ1:N,1:K, C1:N , H|α, β)

p(C1:N|α, β)

(3)

where the numerator of Eq. (3) is deﬁned in Eq. (2). In order to normalize this
posterior distribution we need to marginalize over the latent variables to give
the denominator as shown in Eq. (4):

N(cid:4)

K(cid:4)

(cid:7) N(cid:4)

(cid:7)

(cid:8)

p(C1:N|α, β) =

p(ψn|α)

p(An|ψn)
p(Cn|An, φ1:N,1:K, H)dψnp(φi,k|β)dφi,k

n=1

An

i=1

k=1

Posterior inference of our model is done using approximate message passing
algorithm [17], speciﬁcally we are using Variational Message Passing algorithm
(VMP) [18] in the Infer.Net [19] package. VMP is deterministic approximate
inference algorithm that is guaranteed to converge to some solutions and it works
by using only local message passing operations. Our goal is to infer the individual
behaviors, then use these individual behaviors to predict the choices for the next
game and calculate our accuracy of prediction. This procedure is explained in
the Algorithm 1. Here Cn(t + 1) denotes the actual choices of the next game.
P Cn(t+1) denote predicted choices of the next game and the predicted minority
choice of the next game ˆr(t + 1) is deﬁned as:

(cid:2)

(cid:3)N

ˆr(t + 1) =

0 If
1 Otherwise

n=1

P Cn(t + 1) > N
2

(4)

(5)

290

F. Khawar and Z. Qin

Algorithm 1. Model Inference and Prediction

Parameters: α, β, Number of Agents N , History size K, Number of games G

1: Construct Bayesian inference engine E using Variational Message Passing:
2: for t = 1 → G do
if t = 1 then
3:
4:

Assign symmetric Dirichlet priors i.e. ψ1:N ∼ DirN (α) and φ1:N,1:K ∼

Dir2(β).
else

Assign posterior distributions from the last game as the current prior i.e.
p(ψ1:N (t)) = p(ψ1:N (t−1)|C1:N (t−1), H(t−1)) and p(φ1:N,1:K(t)) = p(φ1:N,1:K(t−
1)|C1:N (t − 1), H(t − 1))

end if
Observe the global data of the current game (choices C1:N (t) and history H(t))
Execute E and calculate the posterior distributions i.e. p(ψ1:N (t)|C1:N (t), H(t))

and input them to E.
and p(φ1:N,1:K(t)|C1:N (t), H(t))

Given the posteriors inferred in Line 9 and history of next game H(t + 1),
execute the engine E to infer Bernoulli distributions of the predicted choices of
the next game P C1:N (t + 1) i.e.
p(P C1:N (t + 1)|ψ1:N (t), A1:N (t + 1), φ1:N,1:K (t), H(t + 1)) ∼ PB(φA1:N (t+1),H(t+1))

5:
6:

7:
8:

9:

10:

11:

To get the predicted choices of the next game, sample from the distributions

inferred in Line 10 i.e. P C1:N (t + 1) ∼ PB(φA1:N (t+1),H(t+1)), P C1:N ∈ {0, 1}

Predict the minority choice of the next game ˆr(t + 1) from Eq. (5)
Calculate the prediction accuracy from Eq. (6)

12:
13:
14: end for

Then the prediction accuracy Acc(t) after observing the game t is deﬁned as:

Acc(t) =

#(ˆr(t+1)=r(t+1))+#(ˆr(t+1)(cid:3)=r(t+1))

#(ˆr(t+1)=r(t+1))

(6)

where the #(.) is an incremental counter, initialized with 0 at t = 1, that incre-
ments by 1 each time its argument (.) is true.

4 Experimental Studies

4.1 Test on Artiﬁcial Data

To test the validity of our model we performed experiments on an artiﬁcial
dataset generated according to the assumptions of the MG and used our model
to learn the individual behavior and then make predictions. To make our ex-
periment more realistic we assumed that some agents follow a random strategy
because in the real-world there are always certain trends in the data that can-
not be either modeled or captured. The random agent makes random choices
between 0 and 1 following a uniform distribution. We further assume that some
agents are adaptive agents and they might divert from their original strategy

A Graphical Model for Collective Behavior Learning Using Minority Games

291

during the experiment. Every adaptive agent maintains its loosing probability
for every history; if this loosing probability is greater than a threshold (0.6 in
our experiments) then the agent changes its strategy (by random picking another
strategy from the strategy space, e.g. [10]). Moreover, the change in strategy can
only occur after every 200 games. We set α = 0.25, β = 0.25, m = 3, N = 31
and use our framework of Algorithm 1 to make predictions on this data. Figure
2 shows the prediction accuracy and error bars for 1000 games with 31 agents,
10% random and 20% adaptive agents, along with the prediction accuracy for
the case of 10% random and no adaptive agents. To obtain averaged results,
the experiment is repeated 10 times. Strategies of adaptive agents change every
200 games resulting in a dip in prediction accuracy and after 1000 games the
accuracy is around 67% with adaptive agents and 84% without adaptive agents.

100

80

60

40

20

y
c
a
r
u
c
c
A
 
e
g
a
t
n
e
c
r
e
P

 

31 Agents(10% Random,20% Adaptive Agents)

Error bars(10% Random,20% Adaptive Agents) 

31 Agents(10% Random, No Adaptive Agents)

Error bars(10% Random, No Adaptive Agents)

0
 
0

200

400

Number of Games

600

800

1000

Fig. 2. Experimental results on artiﬁcial data

4.2 Experiments on Real-World Market Data

The minority game is related to many real-world complex scenarios [5,20,8] in-
cluding ﬁnancial markets. In the following experiments, stock market index data
and the foreign exchange (FX) rate of U.S. Dollar (USD) against Renminbi
(RMB) and Japanese Yen (JPY) against RMB are tested (Table 2). On the
macro-level, the global behavior of these real-world market data appear ran-
dom and unpredictable, but in our experiments we assume the global behavior
of these markets as being generated according to the minority game and then
use the PGM to infer local behaviors to predict possible future trends of these
markets. This framework provides a new way of understanding the relationship
between macro-trends and micro-trends; the combination of these individual be-
havior have the potential of generating very complex and apparently random
global behaviors.

In our experiments we predict whether a stock market index or FX rate will
rise or fall the next day. Thus, rise and fall are the two values corresponding to
the two possible minority choices (choice-0 and choice-1) and one trading day

292

F. Khawar and Z. Qin

65

60

55

50

45

40

y
c
a
r
u
c
c
A
e
g
a

 

t

n
e
c
r
e
P

35
0

200

65

60

55

50

45

40

 

y
c
a
r
u
c
c
A
e
g
a
t
n
e
c
r
e
P

35
0

200

65

60

55

50

45

40

y
c
a
r
u
c
c
A
 
e
g
a
t
n
e
c
r
e
P

35
0

200

Exchange rate of USD againt RMB

400
600
Number of Games

800

1000

CITIC Securities Co.

400
600
Number of Games

800

1000

China Minsheng Banking Co.

400
600
Number of Games

800

1000

65

60

55

50

45

40

y
c
a
r
u
c
c
A
e
g
a

 

t

n
e
c
r
e
P

35
0

200

65

60

55

50

45

40

 

y
c
a
r
u
c
c
A
e
g
a
t
n
e
c
r
e
P

35
0

200

65

60

55

50

45

40

y
c
a
r
u
c
c
A
 
e
g
a
t
n
e
c
r
e
P

35
0

200

Exchange rate of JPY agiant RMB 

600
400
Number of Games

800

1000

Shandong Bohui Paper Industries Co.

400
600
Number of Games

800

1000

Kweichow Moutai Co.

400
600
Number of Games

800

1000

Fig. 3. Experimental results on FX rates and stocks from the Chinese market

corresponds to one game. Formally, for a stock market index (or a FX rate), let
the opening price of that trading day be denoted by Po(t) and the closing price
for that trading day be denoted by Pc(t), then the stock market ﬂuctuation for
that day can be encoded to the minority choice by:
If Pc(t) ≥ Po(t)

(cid:2)

r(t) =

1
0 Otherwise

(7)

(8)

The proposed PGM has two observed variables for the history and choices,
respectively. To obtain the choices from the market data, we ﬁrst need to give
an appropriate number of agents. Given the market data, the number of agents
making choice-1, denoted by #C1, is obtained according to:

#C1 ∝ Po(t) − Pc(t)

Based on the training data, the value of #C1 is scaled appropriately. The quan-
tity Po(t) − Pc(t) is not always positive and is roughly centered around zero,
so we shift it appropriately to make #C1 non-negative. This shifting factor is
greater than the magnitude of its minimum or maximum value and it becomes
the new mean. We then set N equal to twice the shifting factor. Then the choices
are obtained by forming a string of [N − #C1] zeros followed by #C1 ones.

4.3 Experimental Results

The parameters for the PGM used in our experiments are the following: the
hyper-parameters α and β governing the prior Dircihlet distribution of agent

A Graphical Model for Collective Behavior Learning Using Minority Games

293

Table 2. Descriptions of the real market data

Name

Stock index

Test date

Acc after 1000 games (# Agents) N

USD–RMB Exchange Rate
JPY–RMB Exchange Rate

CITIC Securities Co.

Shandong Bohui Paper Industrial Co.

China Minsheng Banking Co.

Kweichou Moutai Co.

-
-

600030
600966
600016
600519

12/04/00-12/02/04
12/04/00-12/02/04
08/11/08-01/09/13
06/08/04-04/10/08
12/19/00-10/21/04
08/27/01-06/29/05

60.78%
51.28%
54.82%
58.79%
52.21%
55.76%

21
29
31
31
21
31

distributions ψ1:N and of choice distributions ψ1:N,1:K, respectively, were both
set to 0.25 as from our multiple experiments we found that these values work
well for most real markets, moreover, the history was assumed to be generated
by agents having a memory length of 3 i.e. m = 3.

In order to get stable and unbiased results we ran the algorithm (described in
Algorithm 1) 10 times for each data set and then calculated the corresponding
error bars. We tested the proposed PGM on 6 datasets, 4 are from real sock
markets and 2 datasets are for RMB exchange rate (shown in Table 2). All the
data was downloadable by searching for each company by its stock index1 and
the exchange rate data is also available online2. Figure 3 shows the prediction
accuracy deﬁned in Eq. (6) for each of the data sets for 1000 games. It also shows
another dashed curve for each dataset that corresponds to random prediction,
based on discrete uniform distribution over [0, 1], for the future trends of the
real datasets. This dashed curve represents the base line as it corresponds to
no learning and just randomly predicting ˆr(t + 1) ∼ U (0, 1). Therefore as long
as our prediction accuracy can be above this curve we can consider that our
proposed inference and prediction technique has learned some local behaviors
that can predict the future trends with more than random accuracy.

The accuracy of USD-RMB exchange rate after 1000 games is around 60.78%
which is high compared to the accuracy obtained for other real-world data sets.
This may suggest that this exchange rate data has some prominent patterns
and these ﬁndings are consistent with the ﬁndings of [12]. Conversely, for JPY
the exchange rate against RMB for the same time period was analyzed and
the result show that our algorithm does not perform much better than random
prediction. In fact for the ﬁrst 700 games the random prediction works better
than our proposed algorithm, however after that our algorithm performs slightly
better with an accuracy of 51.28% after 1000 games. For the other markets
the accuracy is between 52% and 58%. The prediction accuracy on Shandong
Bohui Paper Industrial Co. and CITIC Securities Co. datasets is above random
prediction but for China Minsheng Banking Co. random prediction performs
better for the ﬁrst 350 games, after that the proposed algorithm performs better
on average although the the error bars overlap suggesting that on some occasions
the performance of the proposed technique is comparable to random prediction.
The prediction accuracy for Kweichow Moutai increases to around 60% in the

1

2

http://finance.yahoo.com/
http://bbs.jjxj.org/thread-69632-1-7.html

294

F. Khawar and Z. Qin

ﬁrst 130 games after which it drops indicating a change in the trend for this
market, then after game 280 the accuracy begins to increase again indicating
another major change in the trend, but the increase in accuracy suggests that
the new trend is similar to the trend previously observed by the model.

Table 2 provides the details of the data sets we used in experiments and the
number of agents that were set for each data set based on Eq. (8). For our
simulations we used C# along with Matlab on a 32-bit computer with 3GB of
RAM and two 2.93GHz processors. And for one iteration of Algorithm 1 it takes
around 1.1 sec if the number of agents N is 31. Therefore the total duration for
10 iterations of Algorith 1 for 1000 games is around 3 hours.

5 Conclusions and Future Work

In this paper we modeled the process of generation of the collective behavior of
the minority game with a PGM and showed that we can use the proposed PGM
to decompose the collective behavior by inferring individual agent behavior and
then use them to predict the future trends of real world market data. We ﬁrst
performed experiments on artiﬁcial data to validate our model and then tested
it on the real-world market data. Although ﬁnding patterns of real-world market
data has always been a controversial topic as it violates the eﬃcient-market hy-
pothesis (EMH) [21], however, based on our empirical studies, we indeed found
statistical signiﬁcant patterns by training the new proposed model on history
data. Especially for the USD-RMB exchange rate, we present quantitative ev-
idence that there are some stronger patterns comparing to other FX rate and
stock index. Our future work will focus on applying the framework of Bayesian
learning to learn the hyper-parameters α and β instead of setting them by ex-
perimental evaluation and also to test our framework on more real-world data
but not limited to stock market indexes and FX rates.

Acknowledgements. This research is funded by the NSFC under the Grant
No. 61305047.

References

1. Rapoport, A., Chammah, A., Orwant, C.: Prisoner’s Dilemma: A Study in Conict

and Cooperation. University of Michigan Press, Ann Arbor, Michigan (1965)

2. Smith, V.L.: An experimental study of competitive market behavior. The Journal

of Political Economy 70(2), 111–137 (1962)

3. Farmer, J.D., Foley, D.: The economy needs agent-based modelling. Nature 460,

685–686 (2009)

4. Gode, D., Sunder, S.: Allocative eﬃciency of markets with zero-intelligence traders:
Market as a partial substitute for individual rationality. Journal of Political Econ-
omy 101(1), 119–137 (1993)

5. Johnson, N.F., Jeﬀries, P., Hui, P.M.: Financial market complexity. Oxford

University Press, Oxford (2003)

A Graphical Model for Collective Behavior Learning Using Minority Games

295

6. Qin, Z.: Market mechanism designs with heterogeneous trading agents. In: Pro-
ceedings of Fifth International Conference on Machine Learning and Applications
(ICMLA 2006), pp. 69–74 (2006)

7. Qin, Z., Dong, Y., Wan, T.: Evolutionary models for agent-based complex behavior
modeling. In: Yang, X.-S. (ed.) Artiﬁcial Intelligence, Evolutionary Computing and
Metaheuristics. SCI, vol. 427, pp. 601–631. Springer, Heidelberg (2013)

8. Challet, D., Zhang, Y.C.: Emergence of cooperation and organization in an evolu-

tionary game. Physica A 246, 407–418 (1997)

9. Arthur, W.B.: Bounded rationality and inductive behavior (the el farol problem).

American Economic Review 84, 406–411 (1994)

10. Li, G., Ma, Y., Dong, Y., Qin, Z.: Behavior learning in minority games. In:
Guttmann, C., Dignum, F., Georgeﬀ, M. (eds.) CARE 2009 / 2010. LNCS,
vol. 6066, pp. 125–136. Springer, Heidelberg (2011)

11. Challet, D., Marsili, M., Zhang, Y.C.: Minority Games: Interacting Agents in Fi-

nancial Markets. Oxford University Press, USA (2004)

12. Ma, Y., Li, G., Dong, Y., Qin, Z.: Minority game data mining for stock market
predictions. In: Cao, L., Bazzan, A.L.C., Gorodetsky, V., Mitkas, P.A., Weiss, G.,
Yu, P.S. (eds.) ADMI 2010. LNCS, vol. 5980, pp. 178–189. Springer, Heidelberg
(2010)

13. Du, Y., Dong, Y., Qin, Z., Wan, T.: Exporing market behaviors with evolutionary
mixed-game learning model. In: J ¸edrzejowicz, P., Nguyen, N.T., Hoang, K. (eds.)
ICCCI 2011, Part I. LNCS, vol. 6922, pp. 244–253. Springer, Heidelberg (2011)

14. Bishop, C.M.: Pattern Recognition and Machine Learning. Springer, New York

(2006)

15. Challet, D., Marsili, M., Zhang, Y.C.: Stylized facts of ﬁnancial markets and market

crashes in minority games. Physica A 294, 514–524 (2001)

16. Challet, D., Marsili, M., Zecchina, R.: Statistical mechanics of systems with het-

erogeneous agents: Minority games. Phys. Rev. Lett. 84, 1824–1827 (2000)

17. Koller, D., Friedman, N.: Probabilistic Graphical Models: Principles and Tech-

niques. MIT Press (2009)

18. Winn, J., Bishop, C.M.: Variational message passing. J. Mach. Learn. Res. 6,

661–694 (2005)

19. Minka, T., Winn, J., Guiver, J., Knowles, D.: Infer.NET 2.4, Microsoft Research

Cambridge (2010), http://research.microsoft.com/infernet

20. Lo, T.S., Hui, P.M., Johnson, N.F.: Theory of the evolutionary minority game.

Phys. Rev. E 62, 4393–4396 (2000)

21. Fama, E.: Eﬃcient capital markets: A review of theory and empirical work. Journal

of Finance 25, 383–417 (1970)

